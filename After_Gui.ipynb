{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZ8iZQaenWRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac373f3c-d2aa-44e3-a8a9-2c459b3ff5ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rarfile\n",
            "  Downloading rarfile-4.0-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: rarfile\n",
            "Successfully installed rarfile-4.0\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.2-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.5/268.5 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.2 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n",
            "Collecting simpletransformers\n",
            "  Downloading simpletransformers-0.63.11-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m250.7/250.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.47.0 in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (4.65.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (2022.10.31)\n",
            "Requirement already satisfied: transformers>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (4.30.2)\n",
            "Collecting datasets (from simpletransformers)\n",
            "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (1.2.2)\n",
            "Collecting seqeval (from simpletransformers)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (2.12.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (1.5.3)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (0.13.3)\n",
            "Collecting wandb>=0.10.32 (from simpletransformers)\n",
            "  Downloading wandb-0.15.5-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting streamlit (from simpletransformers)\n",
            "  Downloading streamlit-1.24.0-py2.py3-none-any.whl (8.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece (from simpletransformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.6.0->simpletransformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.6.0->simpletransformers) (0.16.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.6.0->simpletransformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.6.0->simpletransformers) (6.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.6.0->simpletransformers) (0.3.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (8.1.3)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb>=0.10.32->simpletransformers)\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb>=0.10.32->simpletransformers)\n",
            "  Downloading sentry_sdk-1.27.1-py2.py3-none-any.whl (211 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.7/211.7 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb>=0.10.32->simpletransformers)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools (from wandb>=0.10.32->simpletransformers)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb>=0.10.32->simpletransformers)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (3.20.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->simpletransformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->simpletransformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->simpletransformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->simpletransformers) (3.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->simpletransformers) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets->simpletransformers)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->simpletransformers)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->simpletransformers)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->simpletransformers) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->simpletransformers) (3.8.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->simpletransformers) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->simpletransformers) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->simpletransformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->simpletransformers) (3.1.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (4.2.2)\n",
            "Collecting blinker<2,>=1.0.0 (from streamlit->simpletransformers)\n",
            "  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (5.3.1)\n",
            "Collecting importlib-metadata<7,>=1.4 (from streamlit->simpletransformers)\n",
            "  Downloading importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pillow<10,>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (8.4.0)\n",
            "Collecting pympler<2,>=0.9 (from streamlit->simpletransformers)\n",
            "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich<14,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (13.4.2)\n",
            "Requirement already satisfied: tenacity<9,>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (8.2.2)\n",
            "Requirement already satisfied: toml<2 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (4.6.3)\n",
            "Collecting tzlocal<5,>=1.1 (from streamlit->simpletransformers)\n",
            "  Downloading tzlocal-4.3.1-py3-none-any.whl (20 kB)\n",
            "Collecting validators<1,>=0.2 (from streamlit->simpletransformers)\n",
            "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pydeck<1,>=0.1.dev5 (from streamlit->simpletransformers)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (6.3.1)\n",
            "Collecting watchdog (from streamlit->simpletransformers)\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (1.56.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (2.3.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (0.40.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->simpletransformers) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->simpletransformers) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->simpletransformers) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->simpletransformers) (0.12.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.10.32->simpletransformers) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (1.3.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->simpletransformers) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit->simpletransformers) (3.15.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.11.0->streamlit->simpletransformers) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.11.0->streamlit->simpletransformers) (2.14.0)\n",
            "Collecting pytz-deprecation-shim (from tzlocal<5,>=1.1->streamlit->simpletransformers)\n",
            "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from validators<1,>=0.2->streamlit->simpletransformers) (4.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->simpletransformers) (2.1.3)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.19.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.11.0->streamlit->simpletransformers) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->simpletransformers) (3.2.2)\n",
            "Collecting tzdata (from pytz-deprecation-shim->tzlocal<5,>=1.1->streamlit->simpletransformers)\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: seqeval, validators, pathtools\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16165 sha256=0b3ded14acbe381d5b0b6807ab14c85f69ce77057a4d2868ed53263611fddaf3\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19579 sha256=0cb7afd1462bfd489a67e7afdc387d7eafc21765f53fad1dfa74fd075d79a459\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/ed/dd/d3a556ad245ef9dc570c6bcd2f22886d17b0b408dd3bbb9ac3\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=03b1f12556679490dedc3790faed5293d9ba2c3666dd8ea5d8fe6dceb5e16e47\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built seqeval validators pathtools\n",
            "Installing collected packages: sentencepiece, pathtools, xxhash, watchdog, validators, tzdata, smmap, setproctitle, sentry-sdk, pympler, importlib-metadata, docker-pycreds, dill, blinker, pytz-deprecation-shim, pydeck, multiprocess, gitdb, tzlocal, seqeval, GitPython, wandb, streamlit, datasets, simpletransformers\n",
            "  Attempting uninstall: tzlocal\n",
            "    Found existing installation: tzlocal 5.0.1\n",
            "    Uninstalling tzlocal-5.0.1:\n",
            "      Successfully uninstalled tzlocal-5.0.1\n",
            "Successfully installed GitPython-3.1.31 blinker-1.6.2 datasets-2.13.1 dill-0.3.6 docker-pycreds-0.4.0 gitdb-4.0.10 importlib-metadata-6.7.0 multiprocess-0.70.14 pathtools-0.1.2 pydeck-0.8.1b0 pympler-1.0.1 pytz-deprecation-shim-0.1.0.post0 sentencepiece-0.1.99 sentry-sdk-1.27.1 seqeval-1.2.2 setproctitle-1.3.2 simpletransformers-0.63.11 smmap-5.0.0 streamlit-1.24.0 tzdata-2023.3 tzlocal-4.3.1 validators-0.20.0 wandb-0.15.5 watchdog-3.0.0 xxhash-3.2.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unrar is already the newest version (1:5.6.6-2build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.2.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ]
        }
      ],
      "source": [
        "!pip install rarfile\n",
        "! pip install transformers\n",
        "! pip install simpletransformers\n",
        "!apt-get install unrar\n",
        "! pip install fuzzywuzzy\n",
        "! pip install streamlit==1.13.0 -q\n",
        "!pip install joblib\n",
        "from fuzzywuzzy import fuzz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOHW4nr6pO1S",
        "outputId": "3716b1d0-c6aa-445f-d41e-0333939a4750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir Output_Files\n",
        "!mkdir Output_Files/test_data\n",
        "\n",
        "\n",
        "# Define the path to your ZIP file\n",
        "rar_file_path  = \"/content/drive/MyDrive/test_data.rar\"\n",
        "\n",
        "# Define the path to the output directory where you want to extract the contents\n",
        "output_directory = \"/content/Output_Files\"\n",
        "\n",
        "# Run the unzip command to extract the contents of the ZIP file\n",
        "!unrar x \"{rar_file_path}\" \"{output_directory}\""
      ],
      "metadata": {
        "id": "lqCZ3ohqJdYk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b88f1681-4020-40dc-cea3-81893cb5f31a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 5.61 beta 1 freeware      Copyright (c) 1993-2018 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/drive/MyDrive/test_data.rar\n",
            "\n",
            "Extracting  /content/Output_Files/test_data/MTI.csv                      \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠØ© ÙÙŠ Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©.csv     \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠØ© ÙÙŠ Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©.csv     \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø¨Ø±ÙŠØ·Ø§Ù†ÙŠØ© ÙÙŠ Ù…ØµØ±.csv     \b\b\b\b  3%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø¯ÙˆÙ„ÙŠØ© Ù„Ù…ØµØ±.csv     \b\b\b\b  4%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„ÙØ±Ù†Ø³ÙŠØ© ÙÙŠ Ù…ØµØ±.csv     \b\b\b\b  4%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù…ØµØ±ÙŠØ© Ø§Ù„ÙŠØ§Ø¨Ø§Ù†ÙŠØ© Ù„Ù„Ø¹Ù„ÙˆÙ… ÙˆØ§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§.csv     \b\b\b\b  4%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø§Ù„ÙƒÙ„ÙŠØ© Ø§Ù„ÙƒÙ†Ø¯ÙŠØ© Ø§Ù„Ø¯ÙˆÙ„ÙŠØ©.csv     \b\b\b\b  4%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø¬Ø§Ù…Ø¹Ø© 6 Ø£ÙƒØªÙˆØ¨Ø±.csv           \b\b\b\b  6%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø¬Ø§Ù…Ø¹Ø© Ø£Ø³ÙˆØ§Ù†.csv              \b\b\b\b  6%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø¬Ø§Ù…Ø¹Ø© Ø£Ø³ÙŠÙˆØ·.csv              \b\b\b\b  8%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø£Ø²Ù‡Ø±.csv             \b\b\b\b 10%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø¥Ø³ÙƒÙ†Ø¯Ø±ÙŠØ©.csv         \b\b\b\b 11%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø¬Ù„Ø§Ù„Ø©.csv            \b\b\b\b 11%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„ÙÙŠÙˆÙ….csv             \b\b\b\b 12%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©.csv            \b\b\b\b 14%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù…Ù†ØµÙˆØ±Ø©.csv           \b\b\b\b 17%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù…Ù†ÙˆÙÙŠØ©.csv           \b\b\b\b 17%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù…Ù†ÙŠØ§.csv             \b\b\b\b 17%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø¬Ø§Ù…Ø¹Ø© Ø¨Ù†Ù‡Ø§.csv               \b\b\b\b 18%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø¬Ø§Ù…Ø¹Ø© Ø¨Ù†ÙŠ Ø³ÙˆÙŠÙ.csv           \b\b\b\b 19%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø¬Ø§Ù…Ø¹Ø© Ø¬Ù†ÙˆØ¨ Ø§Ù„ÙˆØ§Ø¯ÙŠ.csv        \b\b\b\b 20%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø¬Ø§Ù…Ø¹Ø© Ø­Ù„ÙˆØ§Ù†.csv              \b\b\b\b 22%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø¬Ø§Ù…Ø¹Ø© Ø¯Ù…Ù†Ù‡ÙˆØ±.csv             \b\b\b\b 22%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø¬Ø§Ù…Ø¹Ø© Ø³ÙˆÙ‡Ø§Ø¬.csv              \b\b\b\b 23%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø¬Ø§Ù…Ø¹Ø© Ø·Ù†Ø·Ø§.csv               \b\b\b\b 23%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø¬Ø§Ù…Ø¹Ø© Ø¹ÙŠÙ† Ø´Ù…Ø³.csv            \b\b\b\b 25%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø¬Ø§Ù…Ø¹Ø© Ù‚Ù†Ø§Ø© Ø§Ù„Ø³ÙˆÙŠØ³.csv        \b\b\b\b 25%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ø¬Ø§Ù…Ø¹Ø© ÙƒÙØ± Ø§Ù„Ø´ÙŠØ®.csv          \b\b\b\b 26%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø±ÙƒØ² Ø§Ù„Ù‚Ù„Ø¨ Ù‡Ù„ÙŠÙˆØ¨ÙˆÙ„ÙŠØ³.csv     \b\b\b\b 27%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ 6 Ø§ÙƒØªÙˆØ¨Ø± Ù„Ù„ØªØ£Ù…ÙŠÙ† Ø§Ù„ØµØ­Ù‰.csv     \b\b\b\b 27%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ Ø£Ø­Ù…Ø¯ Ù…Ø§Ù‡Ø± Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ.csv     \b\b\b\b 28%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ø¬Ù„Ø§Ø¡ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ù‰.csv     \b\b\b\b 28%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ø¬Ù†Ø²ÙˆØ±Ù‰ Ø§Ù„ØªØ®ØµØµÙ‰.csv     \b\b\b\b 30%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ø­Ø³ÙŠÙ† Ø§Ù„ØªØ®ØµØµÙŠ.csv     \b\b\b\b 30%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ø¯Ù…Ø±Ø¯Ø§Ø´.csv          \b\b\b\b 32%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ø±Ø­Ù…Ø© Ø§Ù„ØªØ®ØµØµÙŠ.csv     \b\b\b\b 32%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ø³Ù„Ø§Ù… Ø§Ù„Ø¯ÙˆÙ„Ù‰ Ø§Ù„Ù…Ø¹Ø§Ø¯ÙŠ.csv     \b\b\b\b 33%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ø³Ù„Ø§Ù… Ø§Ù„Ø¯ÙˆÙ„Ù‰.csv     \b\b\b\b 39%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„ÙØªØ­ Ø§Ù„Ø¥Ø³Ù„Ø§Ù…Ù‰.csv     \b\b\b\b 39%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ù‚Ø§Ù‡Ø±Ø© Ø§Ù„ØªØ®ØµØµÙŠ.csv     \b\b\b\b 41%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ù…Ù†ÙŠØ±Ø© Ø§Ù„Ø¹Ø§Ù….csv     \b\b\b\b 41%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ù…ÙŠØ±ÙŠÙ„Ø§Ù†Ø¯.csv        \b\b\b\b 41%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ù†Ø²Ù‡Ø© Ø§Ù„Ø¯ÙˆÙ„ÙŠ.csv     \b\b\b\b 42%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ Ø¨Ø§Ø¨ Ø§Ù„Ø´Ø¹Ø±ÙŠØ© (Ø³ÙŠØ¯ Ø¬Ù„Ø§Ù„).csv     \b\b\b\b 42%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ Ø­Ù…ÙŠØ§Øª Ø§Ù„Ø¹Ø¨Ø§Ø³ÙŠØ©.csv     \b\b\b\b 43%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ Ø¯Ø§Ø± Ø§Ù„ÙØ¤Ø§Ø¯.csv        \b\b\b\b 45%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ Ø±Ø§Ø¨Ø¹Ø© Ø§Ù„Ø¹Ø¯ÙˆÙŠØ© Ø§Ù„ØªØ®ØµØµÙ‰.csv     \b\b\b\b 45%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ Ø´Ø±Ù… Ø§Ù„Ø´ÙŠØ® Ø§Ù„Ø¯ÙˆÙ„Ù‰.csv     \b\b\b\b 47%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ Ø¹ÙŠÙ† Ø´Ù…Ø³ Ø§Ù„ØªØ®ØµØµÙŠ.csv     \b\b\b\b 48%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ ØºÙ…Ø±Ø© Ø§Ù„Ø¹Ø³ÙƒØ±ÙŠ.csv      \b\b\b\b 48%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ ÙÙ„Ø³Ø·ÙŠÙ†.csv            \b\b\b\b 49%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ ÙƒÙ„ÙŠÙˆØ¨Ø§ØªØ±.csv          \b\b\b\b 50%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ Ù„ÙˆØ±Ø§Ù†.csv             \b\b\b\b 51%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ Ù…Ø¯ÙŠÙ†Ø© Ù†ØµØ± Ù„Ù„ØªØ£Ù…ÙŠÙ† Ø§Ù„ØµØ­Ù‰.csv     \b\b\b\b 53%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ Ù…Ù†Ø´ÙŠØ© Ø§Ù„Ø¨ÙƒØ±Ù‰ Ø§Ù„Ø¹Ø§Ù….csv     \b\b\b\b 53%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙ‰ Ù†ÙˆØ± Ø§Ù„Ø§Ø³Ù„Ø§Ù….csv       \b\b\b\b 53%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÙŠ Ø¨Ø¯Ø§ÙŠØ©.csv             \b\b\b\b 55%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÛŒ 57357.csv             \b\b\b\b 57%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÛŒ Ø§Ù„Ø§Ù…Ù„.csv             \b\b\b\b 57%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÛŒ Ø§Ù„Ù‚ØµØ± Ø§Ù„Ø¹ÙŠÙ†ÙŠ.csv      \b\b\b\b 64%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø³ØªØ´ÙÛŒ Ø²Ø§ÙŠØ¯ Ø§Ù„Ø¹Ø³ÙƒØ±ÙŠ.csv      \b\b\b\b 64%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø·Ø§Ø± Ø§ÙƒØªÙˆØ¨Ø± Ø§Ù„Ø¬ÙˆÙŠ.csv        \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø·Ø§Ø± Ø§Ù„Ø§Ø³ÙƒÙ†Ø¯Ø±ÙŠØ© Ø§Ù„Ø¯ÙˆÙ„ÙŠ.csv     \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø·Ø§Ø± Ø§Ù„Ø§Ù‚ØµØ± Ø§Ù„Ø¯ÙˆÙ„ÙŠ.csv       \b\b\b\b 68%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø·Ø§Ø± Ø§Ù„Ø´ÙŠØ® Ø¬Ø¨Ø±ÙŠÙ„.csv         \b\b\b\b 68%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø·Ø§Ø± Ø§Ù„Ø¹Ø§ØµÙ…Ø© Ø§Ù„Ø¯ÙˆÙ„ÙŠ.csv      \b\b\b\b 68%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø·Ø§Ø± Ø§Ù„Ù‚Ø§Ù‡Ø±Ø© Ø§Ù„Ø¯ÙˆÙ„ÙŠ 2.csv     \b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø·Ø§Ø± Ø§Ù„Ù‚Ø§Ù‡Ø±Ø© Ø§Ù„Ø¯ÙˆÙ„ÙŠ Ø§Ù„Ù‚Ø¯ÙŠÙ… ØµØ§Ù„Ø© 1.csv     \b\b\b\b 72%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø·Ø§Ø± Ø§Ù„Ù‚Ø§Ù‡Ø±Ø© Ø§Ù„Ø¯ÙˆÙ„ÙŠ ØµØ§Ù„Ø© Ø§Ù„Ø³ÙØ± Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© ÙˆØ§Ù„ÙˆØµÙˆÙ„.csv     \b\b\b\b 72%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø·Ø§Ø± Ø§Ù„Ù‚Ø§Ù‡Ø±Ø© Ø§Ù„Ø¯ÙˆÙ„ÙŠ.csv      \b\b\b\b 76%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø·Ø§Ø± Ø¨ÙˆØ±Ø³Ø¹ÙŠØ¯ Ø§Ù„Ø¯ÙˆÙ„ÙŠ.csv      \b\b\b\b 77%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø·Ø§Ø± Ø³ÙÙ†ÙƒØ³ Ø§Ù„Ø¯ÙˆÙ„Ù‰.csv        \b\b\b\b 78%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø·Ø§Ø± Ø³ÙÙ†ÙƒØ³ Ø§Ù„Ø¯ÙˆÙ„ÙŠ.csv        \b\b\b\b 78%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø·Ø§Ø± Ø´Ø±Ù… Ø§Ù„Ø´ÙŠØ® Ø§Ù„Ø¯ÙˆÙ„ÙŠ.csv     \b\b\b\b 90%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø·Ø§Ø± Ù…Ø±Ø³ÙŠ Ø¹Ù„Ù… Ø§Ù„Ø¯ÙˆÙ„ÙŠ.csv     \b\b\b\b 98%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/Ù…Ø·Ø§Ø± Ù…ØµØ± Ø§Ù„Ù‚Ø¯ÙŠÙ….csv          \b\b\b\b 98%\b\b\b\b\b  OK \n",
            "Extracting  /content/Output_Files/test_data/ÙˆØ²Ø§Ø±Ø© Ø§Ù„ØµØ­Ø© ÙˆØ§Ù„Ø³ÙƒØ§Ù†.csv      \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rarfile\n",
        "\n",
        "# Open the RAR file\n",
        "with rarfile.RarFile(rar_file_path, 'r') as rar_file:\n",
        "    # Print the number of files in the RAR file\n",
        "    print(len(rar_file.namelist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwJiWwCyMYz_",
        "outputId": "7340fbce-a6a4-45a3-da60-77037a92210f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the path to the folder\n",
        "folder_path = \"/content/Output_Files/test_data\"\n",
        "\n",
        "# Use os.listdir() to get a list of all the files in the folder\n",
        "file_names = os.listdir(folder_path)\n",
        "\n",
        "# Use len() to get the number of files in the folder\n",
        "num_files = len(file_names)\n",
        "\n",
        "print(f\"There are {num_files} files in the folder.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYD9i3EJNCzC",
        "outputId": "2415fe40-31a1-41cf-f397-d200454cd1b2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 78 files in the folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from fuzzywuzzy import fuzz\n",
        "import torch\n",
        "import seaborn as sns\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "from nltk.tokenize import word_tokenize\n",
        "import os\n",
        "import nltk\n",
        "import re\n",
        "import joblib\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import seaborn as sns\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#################### Title ######################\n",
        "st.title(\"WELCOME TO OUR RECOMMENDATION SYSTEM ğŸ˜ğŸ˜ğŸ˜\")\n",
        "st.write(\"WE ARE HERE TO HELP YOU...........!!!\")\n",
        "\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "arr = os.listdir('/content/Output_Files/test_data')\n",
        "all_datasets=[]\n",
        "names=[]\n",
        "\n",
        "import streamlit as st\n",
        "st.session_state['max_value']=-10000\n",
        "rec=\" \"\n",
        "emojis = {\n",
        "    \"ğŸ™‚\":\"ÙŠØ¨ØªØ³Ù…\",\n",
        "    \"ğŸ˜‚\":\"ÙŠØ¶Ø­Ùƒ\",\n",
        "    \"ğŸ’”\":\"Ù‚Ù„Ø¨ Ø­Ø²ÙŠÙ†\",\n",
        "    \"ğŸ™‚\":\"ÙŠØ¨ØªØ³Ù…\",\n",
        "    \"â¤ï¸\":\"Ø­Ø¨\",\n",
        "    \"â¤\":\"Ø­Ø¨\",\n",
        "    \"ğŸ˜\":\"Ø­Ø¨\",\n",
        "    \"ğŸ˜­\":\"ÙŠØ¨ÙƒÙŠ\",\n",
        "    \"ğŸ˜¢\":\"Ø­Ø²Ù†\",\n",
        "    \"ğŸ˜”\":\"Ø­Ø²Ù†\",\n",
        "    \"â™¥\":\"Ø­Ø¨\",\n",
        "    \"ğŸ’œ\":\"Ø­Ø¨\",\n",
        "    \"ğŸ˜…\":\"ÙŠØ¶Ø­Ùƒ\",\n",
        "    \"ğŸ™\":\"Ø­Ø²ÙŠÙ†\",\n",
        "    \"ğŸ’•\":\"Ø­Ø¨\",\n",
        "    \"ğŸ’™\":\"Ø­Ø¨\",\n",
        "    \"ğŸ˜\":\"Ø­Ø²ÙŠÙ†\",\n",
        "    \"ğŸ˜Š\":\"Ø³Ø¹Ø§Ø¯Ø©\",\n",
        "    \"ğŸ‘\":\"ÙŠØµÙÙ‚\",\n",
        "    \"ğŸ‘Œ\":\"Ø§Ø­Ø³Ù†Øª\",\n",
        "    \"ğŸ˜´\":\"ÙŠÙ†Ø§Ù…\",\n",
        "    \"ğŸ˜€\":\"ÙŠØ¶Ø­Ùƒ\",\n",
        "    \"ğŸ˜Œ\":\"Ø­Ø²ÙŠÙ†\",\n",
        "    \"ğŸŒ¹\":\"ÙˆØ±Ø¯Ø©\",\n",
        "    \"ğŸ™ˆ\":\"Ø­Ø¨\",\n",
        "    \"ğŸ˜„\":\"ÙŠØ¶Ø­Ùƒ\",\n",
        "    \"ğŸ˜\":\"Ù…Ø­Ø§ÙŠØ¯\",\n",
        "    \"âœŒ\":\"Ù…Ù†ØªØµØ±\",\n",
        "    \"âœ¨\":\"Ù†Ø¬Ù…Ù‡\",\n",
        "    \"ğŸ¤”\":\"ØªÙÙƒÙŠØ±\",\n",
        "    \"ğŸ˜\":\"ÙŠØ³ØªÙ‡Ø²Ø¡\",\n",
        "    \"ğŸ˜’\":\"ÙŠØ³ØªÙ‡Ø²Ø¡\",\n",
        "    \"ğŸ™„\":\"Ù…Ù„Ù„\",\n",
        "    \"ğŸ˜•\":\"Ø¹ØµØ¨ÙŠØ©\",\n",
        "    \"ğŸ˜ƒ\":\"ÙŠØ¶Ø­Ùƒ\",\n",
        "    \"ğŸŒ¸\":\"ÙˆØ±Ø¯Ø©\",\n",
        "    \"ğŸ˜“\":\"Ø­Ø²Ù†\",\n",
        "    \"ğŸ’\":\"Ø­Ø¨\",\n",
        "    \"ğŸ’—\":\"Ø­Ø¨\",\n",
        "    \"ğŸ˜‘\":\"Ù…Ù†Ø²Ø¹Ø¬\",\n",
        "    \"ğŸ’­\":\"ØªÙÙƒÙŠØ±\",\n",
        "    \"ğŸ˜\":\"Ø«Ù‚Ø©\",\n",
        "    \"ğŸ’›\":\"Ø­Ø¨\",\n",
        "    \"ğŸ˜©\":\"Ø­Ø²ÙŠÙ†\",\n",
        "    \"ğŸ’ª\":\"Ø¹Ø¶Ù„Ø§Øª\",\n",
        "    \"ğŸ‘\":\"Ù…ÙˆØ§ÙÙ‚\",\n",
        "    \"ğŸ™ğŸ»\":\"Ø±Ø¬Ø§Ø¡ Ø·Ù„Ø¨\",\n",
        "    \"ğŸ˜³\":\"Ù…ØµØ¯ÙˆÙ…\",\n",
        "    \"ğŸ‘ğŸ¼\":\"ØªØµÙÙŠÙ‚\",\n",
        "    \"ğŸ¶\":\"Ù…ÙˆØ³ÙŠÙ‚ÙŠ\",\n",
        "    \"ğŸŒš\":\"ØµÙ…Øª\",\n",
        "    \"ğŸ’š\":\"Ø­Ø¨\",\n",
        "    \"ğŸ™\":\"Ø±Ø¬Ø§Ø¡ Ø·Ù„Ø¨\",\n",
        "    \"ğŸ’˜\":\"Ø­Ø¨\",\n",
        "    \"ğŸƒ\":\"Ø³Ù„Ø§Ù…\",\n",
        "    \"â˜º\":\"ÙŠØ¶Ø­Ùƒ\",\n",
        "    \"ğŸ¸\":\"Ø¶ÙØ¯Ø¹\",\n",
        "    \"ğŸ˜¶\":\"Ù…ØµØ¯ÙˆÙ…\",\n",
        "    \"âœŒï¸\":\"Ù…Ø±Ø­\",\n",
        "    \"âœ‹ğŸ»\":\"ØªÙˆÙ‚Ù\",\n",
        "    \"ğŸ˜‰\":\"ØºÙ…Ø²Ø©\",\n",
        "    \"ğŸŒ·\":\"Ø­Ø¨\",\n",
        "    \"ğŸ™ƒ\":\"Ù…Ø¨ØªØ³Ù…\",\n",
        "    \"ğŸ˜«\":\"Ø­Ø²ÙŠÙ†\",\n",
        "    \"ğŸ˜¨\":\"Ù…ØµØ¯ÙˆÙ…\",\n",
        "    \"ğŸ¼ \":\"Ù…ÙˆØ³ÙŠÙ‚ÙŠ\",\n",
        "    \"ğŸ\":\"Ù…Ø±Ø­\",\n",
        "    \"ğŸ‚\":\"Ù…Ø±Ø­\",\n",
        "    \"ğŸ’Ÿ\":\"Ø­Ø¨\",\n",
        "    \"ğŸ˜ª\":\"Ø­Ø²Ù†\",\n",
        "    \"ğŸ˜†\":\"ÙŠØ¶Ø­Ùƒ\",\n",
        "    \"ğŸ˜£\":\"Ø§Ø³ØªÙŠØ§Ø¡\",\n",
        "    \"â˜ºï¸\":\"Ø­Ø¨\",\n",
        "    \"ğŸ˜±\":\"ÙƒØ§Ø±Ø«Ø©\",\n",
        "    \"ğŸ˜\":\"ÙŠØ¶Ø­Ùƒ\",\n",
        "    \"ğŸ˜–\":\"Ø§Ø³ØªÙŠØ§Ø¡\",\n",
        "    \"ğŸƒğŸ¼\":\"ÙŠØ¬Ø±ÙŠ\",\n",
        "    \"ğŸ˜¡\":\"ØºØ¶Ø¨\",\n",
        "    \"ğŸš¶\":\"ÙŠØ³ÙŠØ±\",\n",
        "    \"ğŸ¤•\":\"Ù…Ø±Ø¶\",\n",
        "    \"â€¼ï¸\":\"ØªØ¹Ø¬Ø¨\",\n",
        "    \"ğŸ•Š\":\"Ø·Ø§Ø¦Ø±\",\n",
        "    \"ğŸ‘ŒğŸ»\":\"Ø§Ø­Ø³Ù†Øª\",\n",
        "    \"â£\":\"Ø­Ø¨\",\n",
        "    \"ğŸ™Š\":\"Ù…ØµØ¯ÙˆÙ…\",\n",
        "    \"ğŸ’ƒ\":\"Ø³Ø¹Ø§Ø¯Ø© Ù…Ø±Ø­\",\n",
        "    \"ğŸ’ƒğŸ¼\":\"Ø³Ø¹Ø§Ø¯Ø© Ù…Ø±Ø­\",\n",
        "    \"ğŸ˜œ\":\"Ù…Ø±Ø­\",\n",
        "    \"ğŸ‘Š\":\"Ø¶Ø±Ø¨Ø©\",\n",
        "    \"ğŸ˜Ÿ\":\"Ø§Ø³ØªÙŠØ§Ø¡\",\n",
        "    \"ğŸ’–\":\"Ø­Ø¨\",\n",
        "    \"ğŸ˜¥\":\"Ø­Ø²Ù†\",\n",
        "    \"ğŸ»\":\"Ù…ÙˆØ³ÙŠÙ‚ÙŠ\",\n",
        "    \"âœ’\":\"ÙŠÙƒØªØ¨\",\n",
        "    \"ğŸš¶ğŸ»\":\"ÙŠØ³ÙŠØ±\",\n",
        "    \"ğŸ’\":\"Ø§Ù„Ù…Ø§Ø¸\",\n",
        "    \"ğŸ˜·\":\"ÙˆØ¨Ø§Ø¡ Ù…Ø±Ø¶\",\n",
        "    \"â˜\":\"ÙˆØ§Ø­Ø¯\",\n",
        "    \"ğŸš¬\":\"ØªØ¯Ø®ÙŠÙ†\",\n",
        "    \"ğŸ’\" : \"ÙˆØ±Ø¯\",\n",
        "    \"ğŸŒ\" : \"Ø´Ù…Ø³\",\n",
        "    \"ğŸ‘†\" : \"Ø§Ù„Ø§ÙˆÙ„\",\n",
        "    \"âš ï¸\" :\"ØªØ­Ø°ÙŠØ±\",\n",
        "    \"ğŸ¤—\" : \"Ø§Ø­ØªÙˆØ§Ø¡\",\n",
        "    \"âœ–ï¸\": \"ØºÙ„Ø·\",\n",
        "    \"ğŸ“\"  : \"Ù…ÙƒØ§Ù†\",\n",
        "    \"ğŸ‘¸\" : \"Ù…Ù„ÙƒÙ‡\",\n",
        "    \"ğŸ‘‘\" : \"ØªØ§Ø¬\",\n",
        "    \"âœ”ï¸\" : \"ØµØ­\",\n",
        "    \"ğŸ’Œ\": \"Ù‚Ù„Ø¨\",\n",
        "    \"ğŸ˜²\" : \"Ù…Ù†Ø¯Ù‡Ø´\",\n",
        "    \"ğŸ’¦\": \"Ù…Ø§Ø¡\",\n",
        "    \"ğŸš«\" : \"Ø®Ø·Ø§\",\n",
        "    \"ğŸ‘ğŸ»\" : \"Ø¨Ø±Ø§ÙÙˆ\",\n",
        "    \"ğŸŠ\" :\"ÙŠØ³Ø¨Ø­\",\n",
        "    \"ğŸ‘ğŸ»\": \"ØªÙ…Ø§Ù…\",\n",
        "    \"â­•ï¸\" :\"Ø¯Ø§Ø¦Ø±Ù‡ ÙƒØ¨ÙŠØ±Ù‡\",\n",
        "    \"ğŸ·\" : \"Ø³Ø§ÙƒØ³ÙÙˆÙ†\",\n",
        "    \"ğŸ‘‹\": \"ØªÙ„ÙˆÙŠØ­ Ø¨Ø§Ù„ÙŠØ¯\",\n",
        "    \"âœŒğŸ¼\": \"Ø¹Ù„Ø§Ù…Ù‡ Ø§Ù„Ù†ØµØ±\",\n",
        "    \"ğŸŒ\":\"Ù…Ø¨ØªØ³Ù…\",\n",
        "    \"â¿\"  : \"Ø¹Ù‚Ø¯Ù‡ Ù…Ø²Ø¯ÙˆØ¬Ù‡\",\n",
        "    \"ğŸ’ªğŸ¼\" : \"Ù‚ÙˆÙŠ\",\n",
        "    \"ğŸ“©\":  \"ØªÙˆØ§ØµÙ„ Ù…Ø¹ÙŠ\",\n",
        "    \"â˜•ï¸\": \"Ù‚Ù‡ÙˆÙ‡\",\n",
        "    \"ğŸ˜§\" : \"Ù‚Ù„Ù‚ Ùˆ ØµØ¯Ù…Ø©\",\n",
        "    \"ğŸ—¨\": \"Ø±Ø³Ø§Ù„Ø©\",\n",
        "    \"â—ï¸\" :\"ØªØ¹Ø¬Ø¨\",\n",
        "    \"ğŸ™†ğŸ»\": \"Ø§Ø´Ø§Ø±Ù‡ Ù…ÙˆØ§ÙÙ‚Ù‡\",\n",
        "    \"ğŸ‘¯\" :\"Ø§Ø®ÙˆØ§Øª\",\n",
        "    \"Â©\" :  \"Ø±Ù…Ø²\",\n",
        "    \"ğŸ‘µğŸ½\" :\"Ø³ÙŠØ¯Ù‡ Ø¹Ø¬ÙˆØ²Ù‡\",\n",
        "    \"ğŸ£\": \"ÙƒØªÙƒÙˆØª\",\n",
        "    \"ğŸ™Œ\": \"ØªØ´Ø¬ÙŠØ¹\",\n",
        "    \"ğŸ™‡\": \"Ø´Ø®Øµ ÙŠÙ†Ø­Ù†ÙŠ\",\n",
        "    \"ğŸ‘ğŸ½\":\"Ø§ÙŠØ¯ÙŠ Ù…ÙØªÙˆØ­Ù‡\",\n",
        "    \"ğŸ‘ŒğŸ½\": \"Ø¨Ø§Ù„Ø¸Ø¨Ø·\",\n",
        "    \"â‰ï¸\" : \"Ø§Ø³ØªÙ†ÙƒØ§Ø±\",\n",
        "    \"âš½ï¸\": \"ÙƒÙˆØ±Ù‡\",\n",
        "    \"ğŸ•¶\" :\"Ø­Ø¨\",\n",
        "    \"ğŸˆ\" :\"Ø¨Ø§Ù„ÙˆÙ†\",\n",
        "    \"ğŸ€\":    \"ÙˆØ±Ø¯Ù‡\",\n",
        "    \"ğŸ’µ\":  \"ÙÙ„ÙˆØ³\",\n",
        "    \"ğŸ˜‹\":  \"Ø¬Ø§Ø¦Ø¹\",\n",
        "    \"ğŸ˜›\":  \"ÙŠØºÙŠØ¸\",\n",
        "    \"ğŸ˜ \":  \"ØºØ§Ø¶Ø¨\",\n",
        "    \"âœğŸ»\":  \"ÙŠÙƒØªØ¨\",\n",
        "    \"ğŸŒ¾\":  \"Ø§Ø±Ø²\",\n",
        "    \"ğŸ‘£\":  \"Ø§Ø«Ø± Ù‚Ø¯Ù…ÙŠÙ†\",\n",
        "    \"âŒ\":\"Ø±ÙØ¶\",\n",
        "    \"ğŸŸ\":\"Ø·Ø¹Ø§Ù…\",\n",
        "    \"ğŸ‘¬\":\"ØµØ¯Ø§Ù‚Ø©\",\n",
        "    \"ğŸ°\":\"Ø§Ø±Ù†Ø¨\",\n",
        "    \"â˜‚\":\"Ù…Ø·Ø±\",\n",
        "    \"âšœ\":\"Ù…Ù…Ù„ÙƒØ© ÙØ±Ù†Ø³Ø§\",\n",
        "    \"ğŸ‘\":\"Ø®Ø±ÙˆÙ\",\n",
        "    \"ğŸ—£\":\"ØµÙˆØª Ù…Ø±ØªÙØ¹\",\n",
        "    \"ğŸ‘ŒğŸ¼\":\"Ø§Ø­Ø³Ù†Øª\",\n",
        "    \"â˜˜\":\"Ù…Ø±Ø­\",\n",
        "    \"ğŸ˜®\":\"ØµØ¯Ù…Ø©\",\n",
        "    \"ğŸ˜¦\":\"Ù‚Ù„Ù‚\",\n",
        "    \"â­•\":\"Ø§Ù„Ø­Ù‚\",\n",
        "    \"âœï¸\":\"Ù‚Ù„Ù…\",\n",
        "    \"â„¹\":\"Ù…Ø¹Ù„ÙˆÙ…Ø§Øª\",\n",
        "    \"ğŸ™ğŸ»\":\"Ø±ÙØ¶\",\n",
        "    \"âšªï¸\":\"Ù†Ø¶Ø§Ø±Ø© Ù†Ù‚Ø§Ø¡\",\n",
        "    \"ğŸ¤\":\"Ø­Ø²Ù†\",\n",
        "    \"ğŸ’«\":\"Ù…Ø±Ø­\",\n",
        "    \"ğŸ’\":\"Ø­Ø¨\",\n",
        "    \"ğŸ”\":\"Ø·Ø¹Ø§Ù…\",\n",
        "    \"â¤ï¸\":\"Ø­Ø¨\",\n",
        "    \"âœˆï¸\":\"Ø³ÙØ±\",\n",
        "    \"ğŸƒğŸ»â€â™€ï¸\":\"ÙŠØ³ÙŠØ±\",\n",
        "    \"ğŸ³\":\"Ø°ÙƒØ±\",\n",
        "    \"ğŸ¤\":\"Ù…Ø§ÙŠÙƒ ØºÙ†Ø§Ø¡\",\n",
        "    \"ğŸ¾\":\"ÙƒØ±Ù‡\",\n",
        "    \"ğŸ”\":\"Ø¯Ø¬Ø§Ø¬Ø©\",\n",
        "    \"ğŸ™‹\":\"Ø³Ø¤Ø§Ù„\",\n",
        "    \"ğŸ“®\":\"Ø¨Ø­Ø±\",\n",
        "    \"ğŸ’‰\":\"Ø¯ÙˆØ§Ø¡\",\n",
        "    \"ğŸ™ğŸ¼\":\"Ø±Ø¬Ø§Ø¡ Ø·Ù„Ø¨\",\n",
        "    \"ğŸ’‚ğŸ¿ \":\"Ø­Ø§Ø±Ø³\",\n",
        "    \"ğŸ¬\":\"Ø³ÙŠÙ†Ù…Ø§\",\n",
        "    \"â™¦ï¸\":\"Ù…Ø±Ø­\",\n",
        "    \"ğŸ’¡\":\"Ù‚ÙƒØ±Ø©\",\n",
        "    \"â€¼\":\"ØªØ¹Ø¬Ø¨\",\n",
        "    \"ğŸ‘¼\":\"Ø·ÙÙ„\",\n",
        "    \"ğŸ”‘\":\"Ù…ÙØªØ§Ø­\",\n",
        "    \"â™¥ï¸\":\"Ø­Ø¨\",\n",
        "    \"ğŸ•‹\":\"ÙƒØ¹Ø¨Ø©\",\n",
        "    \"ğŸ“\":\"Ø¯Ø¬Ø§Ø¬Ø©\",\n",
        "    \"ğŸ’©\":\"Ù…Ø¹ØªØ±Ø¶\",\n",
        "    \"ğŸ‘½\":\"ÙØ¶Ø§Ø¦ÙŠ\",\n",
        "    \"â˜”ï¸\":\"Ù…Ø·Ø±\",\n",
        "    \"ğŸ·\":\"Ø¹ØµÙŠØ±\",\n",
        "    \"ğŸŒŸ\":\"Ù†Ø¬Ù…Ø©\",\n",
        "    \"â˜ï¸\":\"Ø³Ø­Ø¨\",\n",
        "    \"ğŸ‘ƒ\":\"Ù…Ø¹ØªØ±Ø¶\",\n",
        "    \"ğŸŒº\":\"Ù…Ø±Ø­\",\n",
        "    \"ğŸ”ª\":\"Ø³ÙƒÙŠÙ†Ø©\",\n",
        "    \"â™¨\":\"Ø³Ø®ÙˆÙ†ÙŠØ©\",\n",
        "    \"ğŸ‘ŠğŸ¼\":\"Ø¶Ø±Ø¨\",\n",
        "    \"âœ\":\"Ù‚Ù„Ù…\",\n",
        "    \"ğŸš¶ğŸ¾â€â™€ï¸\":\"ÙŠØ³ÙŠØ±\",\n",
        "    \"ğŸ‘Š\":\"Ø¶Ø±Ø¨Ø©\",\n",
        "    \"â—¾ï¸\":\"ÙˆÙ‚Ù\",\n",
        "    \"ğŸ˜š\":\"Ø­Ø¨\",\n",
        "    \"ğŸ”¸\":\"Ù…Ø±Ø­\",\n",
        "    \"ğŸ‘ğŸ»\":\"Ù„Ø§ ÙŠØ¹Ø¬Ø¨Ù†ÙŠ\",\n",
        "    \"ğŸ‘ŠğŸ½\":\"Ø¶Ø±Ø¨Ø©\",\n",
        "    \"ğŸ˜™\":\"Ø­Ø¨\",\n",
        "    \"ğŸ¥\":\"ØªØµÙˆÙŠØ±\",\n",
        "    \"ğŸ‘‰\":\"Ø¬Ø°Ø¨ Ø§Ù†ØªØ¨Ø§Ù‡\",\n",
        "    \"ğŸ‘ğŸ½\":\"ÙŠØµÙÙ‚\",\n",
        "    \"ğŸ’ªğŸ»\":\"Ø¹Ø¶Ù„Ø§Øª\",\n",
        "    \"ğŸ´\":\"Ø§Ø³ÙˆØ¯\",\n",
        "    \"ğŸ”¥\":\"Ø­Ø±ÙŠÙ‚\",\n",
        "    \"ğŸ˜¬\":\"Ø¹Ø¯Ù… Ø§Ù„Ø±Ø§Ø­Ø©\",\n",
        "    \"ğŸ‘ŠğŸ¿\":\"ÙŠØ¶Ø±Ø¨\",\n",
        "    \"ğŸŒ¿\":\"ÙˆØ±Ù‚Ù‡ Ø´Ø¬Ø±Ù‡\",\n",
        "    \"âœ‹ğŸ¼\":\"ÙƒÙ Ø§ÙŠØ¯\",\n",
        "    \"ğŸ‘\":\"Ø§ÙŠØ¯ÙŠ Ù…ÙØªÙˆØ­Ù‡\",\n",
        "    \"â˜ ï¸\":\"ÙˆØ¬Ù‡ Ù…Ø±Ø¹Ø¨\",\n",
        "    \"ğŸ‰\":\"ÙŠÙ‡Ù†Ø¦\",\n",
        "    \"ğŸ”•\" :\"ØµØ§Ù…Øª\",\n",
        "    \"ğŸ˜¿\":\"ÙˆØ¬Ù‡ Ø­Ø²ÙŠÙ†\",\n",
        "    \"â˜¹ï¸\":\"ÙˆØ¬Ù‡ ÙŠØ§Ø¦Ø³\",\n",
        "    \"ğŸ˜˜\" :\"Ø­Ø¨\",\n",
        "    \"ğŸ˜°\" :\"Ø®ÙˆÙ Ùˆ Ø­Ø²Ù†\",\n",
        "    \"ğŸŒ¼\":\"ÙˆØ±Ø¯Ù‡\",\n",
        "    \"ğŸ’‹\":  \"Ø¨ÙˆØ³Ù‡\",\n",
        "    \"ğŸ‘‡\":\"Ù„Ø§Ø³ÙÙ„\",\n",
        "    \"â£ï¸\":\"Ø­Ø¨\",\n",
        "    \"ğŸ§\":\"Ø³Ù…Ø§Ø¹Ø§Øª\",\n",
        "    \"ğŸ“\":\"ÙŠÙƒØªØ¨\",\n",
        "    \"ğŸ˜‡\":\"Ø¯Ø§ÙŠØ®\",\n",
        "    \"ğŸ˜ˆ\":\"Ø±Ø¹Ø¨\",\n",
        "    \"ğŸƒ\":\"ÙŠØ¬Ø±ÙŠ\",\n",
        "    \"âœŒğŸ»\":\"Ø¹Ù„Ø§Ù…Ù‡ Ø§Ù„Ù†ØµØ±\",\n",
        "    \"ğŸ”«\":\"ÙŠØ¶Ø±Ø¨\",\n",
        "    \"â—ï¸\":\"ØªØ¹Ø¬Ø¨\",\n",
        "    \"ğŸ‘\":\"ØºÙŠØ± Ù…ÙˆØ§ÙÙ‚\",\n",
        "    \"ğŸ”\":\"Ù‚ÙÙ„\",\n",
        "    \"ğŸ‘ˆ\":\"Ù„Ù„ÙŠÙ…ÙŠÙ†\",\n",
        "    \"â„¢\":\"Ø±Ù…Ø²\",\n",
        "    \"ğŸš¶ğŸ½\":\"ÙŠØªÙ…Ø´ÙŠ\",\n",
        "    \"ğŸ˜¯\":\"Ù…ØªÙØ§Ø¬Ø£\",\n",
        "    \"âœŠ\":\"ÙŠØ¯ Ù…ØºÙ„Ù‚Ù‡\",\n",
        "    \"ğŸ˜»\":\"Ø§Ø¹Ø¬Ø§Ø¨\",\n",
        "    \"ğŸ™‰\" :\"Ù‚Ø±Ø¯\",\n",
        "    \"ğŸ‘§\":\"Ø·ÙÙ„Ù‡ ØµØºÙŠØ±Ù‡\",\n",
        "    \"ğŸ”´\":\"Ø¯Ø§Ø¦Ø±Ù‡ Ø­Ù…Ø±Ø§Ø¡\",\n",
        "    \"ğŸ’ªğŸ½\":\"Ù‚ÙˆÙ‡\",\n",
        "    \"ğŸ’¤\":\"ÙŠÙ†Ø§Ù…\",\n",
        "    \"ğŸ‘€\":\"ÙŠÙ†Ø¸Ø±\",\n",
        "    \"âœğŸ»\":\"ÙŠÙƒØªØ¨\",\n",
        "    \"â„ï¸\":\"ØªÙ„Ø¬\",\n",
        "    \"ğŸ’€\":\"Ø±Ø¹Ø¨\",\n",
        "    \"ğŸ˜¤\":\"ÙˆØ¬Ù‡ Ø¹Ø§Ø¨Ø³\",\n",
        "    \"ğŸ–‹\":\"Ù‚Ù„Ù…\",\n",
        "    \"ğŸ©\":\"ÙƒØ§Ø¨\",\n",
        "    \"â˜•ï¸\":\"Ù‚Ù‡ÙˆÙ‡\",\n",
        "    \"ğŸ˜¹\":\"Ø¶Ø­Ùƒ\",\n",
        "    \"ğŸ’“\":\"Ø­Ø¨\",\n",
        "    \"â˜„ï¸ \":\"Ù†Ø§Ø±\",\n",
        "    \"ğŸ‘»\":\"Ø±Ø¹Ø¨\",\n",
        "    \"â\":\"Ø®Ø·Ø¡\",\n",
        "    \"ğŸ¤®\":\"Ø­Ø²Ù†\",\n",
        "    'ğŸ»':\"Ø§Ø­Ù…Ø±\"\n",
        "    }\n",
        "\n",
        "#load model\n",
        "model=joblib.load('/content/drive/MyDrive/new_model(1).pkl')\n",
        "\n",
        "##################### hendle_emojis ###############################\n",
        "def hendle_emojis(text,emojis):\n",
        "  li=[]\n",
        "  for i in word_tokenize(text):\n",
        "    for x in i :\n",
        "      if x not in emojis.keys():\n",
        "        li.append(i)\n",
        "        break\n",
        "      else:\n",
        "        li.append(emojis[x])\n",
        "  return \" \".join(li)\n",
        "####################### data cleaning ##########################\n",
        "def data_cleaning(x):\n",
        "    new = re.sub(r'[^Ø¡-ÙŠ]',' ',x)\n",
        "    return new\n",
        "################remove_diacritics##############################\n",
        "def remove_diacritics(text):\n",
        "    arabic_diacritics = re.compile(\"\"\" Ù‘    | # Tashdid\n",
        "                             Ù    | # Fatha\n",
        "                             Ù‹    | # Tanwin Fath\n",
        "                             Ù    | # Damma\n",
        "                             ÙŒ    | # Tanwin Damm\n",
        "                             Ù    | # Kasra\n",
        "                             Ù    | # Tanwin Kasr\n",
        "                             Ù’    | # Sukun\n",
        "                             Ù€     # Tatwil/Kashida\n",
        "                         \"\"\", re.VERBOSE)\n",
        "    text = re.sub(arabic_diacritics, '', str(text))\n",
        "    return text\n",
        "################   decoding outputs   ##############################\n",
        "def decode(x):\n",
        "  if x == 0:\n",
        "    return \"Negative\"\n",
        "  elif x == 1:\n",
        "    return \"Neutral\"\n",
        "  else:\n",
        "    return \"Positive\"\n",
        "##############################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "counter=0\n",
        "num= st.number_input(\"Enter The number of inputs \")\n",
        "for i in range (int(num)):\n",
        "\n",
        "    file_name = st.text_input(\" Input Number \" +str(counter+1),\"\")\n",
        "    counter+=1\n",
        "    if file_name==\"\":\n",
        "        break\n",
        "\n",
        "    if file_name+\".csv\" not in arr:\n",
        "      max_index =0\n",
        "      max=fuzz.ratio(file_name,arr[0])\n",
        "    for i in range(len(arr)):\n",
        "      x=fuzz.ratio(file_name+\".csv\",arr[i])\n",
        "      if x > max:\n",
        "        max_index=i\n",
        "        max=x\n",
        "    file_name=arr[max_index]\n",
        "    names.append(file_name)\n",
        "\n",
        "for z in names:\n",
        "    dataset = pd.read_csv(f'/content/Output_Files/test_data/{z}')\n",
        "    dataset.columns.values[0] = \"text\"\n",
        "    dataset['label'] =0\n",
        "    #st.dataframe(dataset)\n",
        "    dataset=dataset.dropna()\n",
        "    dataset=dataset.drop_duplicates()\n",
        "    dataset['text'] = dataset['text'].apply(hendle_emojis, args=[emojis])\n",
        "    dataset['text'] = dataset['text'].apply(lambda x: data_cleaning(x))\n",
        "    dataset['text'] = dataset['text'].apply(lambda x: remove_diacritics(x))\n",
        "    dataset = dataset.dropna()\n",
        "    dataset = dataset.drop_duplicates()\n",
        "    result, model_outputs, wrong_predictions = model.eval_model(dataset)\n",
        "\n",
        "    # Get the index of the maximum value for each row\n",
        "\n",
        "    max_index_per_row = np.argmax(model_outputs, axis=1)\n",
        "    decoded_labels = [decode(x) for x in max_index_per_row ]\n",
        "\n",
        "\n",
        "# Print the decoded labels\n",
        "    data = [[text, label] for text, label in zip(dataset['text'], decoded_labels)]\n",
        "    new_df = pd.DataFrame(data, columns=['text', 'label'])\n",
        "    all_datasets.append(new_df)\n",
        "\n",
        "    #Count the number of positive, negative, and neutral labels\n",
        "    pos_count = decoded_labels.count('Positive')\n",
        "    neg_count = decoded_labels.count('Negative')\n",
        "    neu_count = decoded_labels.count('Neutral')\n",
        "\n",
        "    #Visualize the counts using Streamlit and Plotly\n",
        "    import streamlit as st\n",
        "    import plotly.graph_objects as go\n",
        "\n",
        "    st.write(\"Info about:\", re.sub(r'[^Ø¡-ÙŠ ]', ' ', z))\n",
        "    st.write('Number of Positive Labels:', pos_count)\n",
        "    st.write('Number of Negative Labels:', neg_count)\n",
        "    st.write('Number of Neutral Labels:', neu_count)\n",
        "\n",
        "    labels = ['Positive', 'Negative', 'Neutral']\n",
        "    counts = [pos_count, neg_count, neu_count]\n",
        "\n",
        "    fig = go.Figure(data=[go.Pie(labels=labels, values=counts)])\n",
        "\n",
        "# Adjust the height and width of the plot\n",
        "    fig.update_layout(\n",
        "    height=500,  # Adjust the height to your desired size\n",
        "    width=500,  # Adjust the width to your desired size\n",
        "    )\n",
        "\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "    if (pos_count /neg_count) > st.session_state['max_value']:\n",
        "       rec = re.sub(r'[^Ø¡-ÙŠ ]', ' ', z)\n",
        "       st.session_state['max_value'] = (pos_count / neg_count)\n",
        "\n",
        "\n",
        "\n",
        "st.write(\"HERE'S THE BEST THING FOR YOU ğŸ˜ğŸ‘‰\", f\"{rec} \\U0001F48E\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb6lnk6IIGqH",
        "outputId": "ec05ec10-79f5-4cc6-e276-b97f18e27104"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!streamlit run /content/app.py & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTCKuI8aP3ea",
        "outputId": "7ae34daf-8ac3-42f4-91de-c0e8949f2baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.91.185.219\n",
            "2023-07-07 00:49:26.661 INFO    numexpr.utils: NumExpr defaulting to 2 threads.\n",
            "[#######...........] / extract:localtunnel: verb lock using /root/.npm/_locks/s\u001b[0m\u001b[K\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.91.185.219:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.553s\n",
            "your url is: https://giant-walls-poke.loca.lt\n",
            "/usr/local/lib/python3.10/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "2023-07-07 00:50:09.667932: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/simpletransformers/classification/classification_model.py:1454: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
            "  warnings.warn(\n",
            "2023-07-07 00:50:29.688  Converting to features started. Cache is not used.\n",
            "  0% 2/895 [00:00<02:24,  6.17it/s]\n",
            "2023-07-07 00:50:30.086  Saving features into cached file cache_dir/cached_dev_bert_128_3_2\n",
            "Running Evaluation: 100% 112/112 [00:02<00:00, 48.96it/s]\n",
            "2023-07-07 00:50:32.387 {'mcc': 0.0, 'f1_multiclass': (0.943508941623997, 0.9438080057204999), 'eval_loss': 4.528242428387914}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hzVMAfcu2Uv2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}